{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a882c1",
   "metadata": {},
   "source": [
    "# Creating segmenation masks \n",
    "### Creating masks using the binary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import os\n",
    "import random\n",
    "import metrics\n",
    "import time\n",
    "\n",
    "import constants as cst\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "#import torch.nn.functional as F\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "\n",
    "from unet import UNET\n",
    "import utils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a16952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(model, image, device, transform, out_threshold=0.5):\n",
    "    with torch.no_grad():\n",
    "        x = image\n",
    "        logits = model(x.to(device))\n",
    "        logits = transform(logits)\n",
    "        y_pred = nn.Softmax(dim=1)(logits)\n",
    "        proba = y_pred.detach().cpu().squeeze(0).numpy()[1, :, :]\n",
    "        return proba > out_threshold\n",
    "\n",
    "\n",
    "TERMS = cst.COMBINED_TERM\n",
    "    \n",
    "# Images that belong to every testing set\n",
    "names = [\"120220_4xzoom_v_fish 16.jpg\",\n",
    "        \"120220_4xzoom_v2_fish 14.jpg\",\n",
    "        \"26022020 inx +- 4xzoom fish08 v3.jpg\",\n",
    "        \"26022020 inx +- 4xzoom fish11 v.jpg\",\n",
    "        \"120220_4xzoom_v_fish 01.jpg\",\n",
    "        \"120220_4xzoom_v_fish 09.jpg\",\n",
    "        \"120220_4xzoom_v1_fish 19.jpg\",\n",
    "        \"120220_4xzoom_v2_fish 15.jpg\",\n",
    "        \"120220_4xzoom_v2_fish 17.jpg\",\n",
    "        \"120220_4xzoom_v1_fish 23.jpg\",\n",
    "        \"120220_4xzoom_v2_fish 21.jpg\",\n",
    "        \"120220_4xzoom_v1_fish 11.jpg\"]\n",
    "\n",
    "img_names = [\"img1\",\n",
    "             \"img2\",\n",
    "             \"img3\",\n",
    "             \"img4\",\n",
    "             \"img5\",\n",
    "             \"img6\",\n",
    "             \"img7\",\n",
    "             \"img8\",\n",
    "             \"img9\",\n",
    "             \"img10\",\n",
    "             \"img11\",\n",
    "             \"img12\"]\n",
    "\n",
    "random.seed(cst.SEED)\n",
    "torch.manual_seed(cst.SEED)\n",
    "np.random.seed(cst.SEED)\n",
    "\n",
    "# One model per annotation\n",
    "model_names = [\"br1_Focal_Fold_1_Epoch_54_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "              \"br2_CE_Fold_2_Epoch_248_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "              \"cb_Tversky_Fold_2_Epoch_250_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "              \"ch_Tversky_Fold_2_Epoch_250_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "              \"cl_Focal_Fold_1_Epoch_71_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "              \"d_CE_Fold_3_Epoch_247_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "              \"en_Tversky_Fold_2_Epoch_227_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "              \"hm_Tversky_Fold_0_Epoch_247_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "              \"m_CE_Fold_2_Epoch_250_MaxEpochs_250_Adam_LR_0.0001 (1).pth\",\n",
    "              \"n_Focal_Fold_0_Epoch_81_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "              \"oc_Focal_Fold_1_Epoch_103_MaxEpochs_250_Adam_LR_0.0001 (1).pth\",\n",
    "              \"op_Focal_Fold_2_Epoch_48_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "              \"p_CE_Fold_3_Epoch_162_MaxEpochs_1000_Adam_LR_0.0001.pth\",\n",
    "              \"vc_Tversky_Fold_2_Epoch_153_MaxEpochs_250_Adam_LR_0.0001.pth\"]\n",
    "\n",
    "\n",
    "model_path = os.path.join(cst.DIR, \"final_normal\")\n",
    "save_path = os.path.join(cst.DIR, \"pred_normal_best\")\n",
    "\n",
    "# One threshold per annotation\n",
    "thresholds = [0.14,\n",
    "              0.01,\n",
    "              0.08,\n",
    "              0.06,\n",
    "              0.12,\n",
    "              0.06,\n",
    "              0.04,\n",
    "              0.02,\n",
    "              0.02,\n",
    "              0.24,\n",
    "              0.2,\n",
    "              0.18,\n",
    "              0.12,\n",
    "              0.02]\n",
    "\n",
    "# One color per annotation\n",
    "all_colors = [\"red\",\n",
    "          \"coral\",\n",
    "          \"sandybrown\",\n",
    "          \"gold\",\n",
    "          \"greenyellow\",\n",
    "          \"seagreen\",\n",
    "          \"cyan\",\n",
    "          \"steelblue\",\n",
    "          \"blue\",\n",
    "          \"mediumslateblue\",\n",
    "          \"darkorchid\",\n",
    "          \"magenta\",\n",
    "          \"lightpink\",\n",
    "          \"dimgrey\"]\n",
    "\n",
    "loss_name = \"best\"\n",
    "fold = 0\n",
    "\n",
    "SIZE = (384, 512)\n",
    "\n",
    "\n",
    "DEVICE_NAME = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE_NAME = 'cuda:0'\n",
    "DEVICE = torch.device(DEVICE_NAME)\n",
    "\n",
    "transform_tensor = transforms.ToTensor()\n",
    "transform = transforms.Compose([transforms.Resize(SIZE),\n",
    "                                transforms.Pad((0, 64, 0, 64))])\n",
    "untransform = transforms.Compose([transforms.CenterCrop(SIZE),\n",
    "                                 transforms.Resize((1932, 2576))])\n",
    "\n",
    "for i in range(len(names)):\n",
    "    name_img = names[i]\n",
    "    save_name = img_names[i]\n",
    "    \n",
    "    img_path = os.path.join(cst.DIR, \"images\")\n",
    "    \n",
    "    img = transform_tensor(Image.open(os.path.join(img_path, name_img)))\n",
    "    img = img[:3,:,:]\n",
    "    img_copy = img\n",
    "    img = img.unsqueeze(dim=0)\n",
    "    \n",
    "    all_groundtruth = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    for t in range(len(TERMS)):\n",
    "        print(\"Image:\" , name_img)\n",
    "        print(\"Model:\", model_names[t])\n",
    "        print(\"Threshold:\", thresholds[t])\n",
    "        model_name = model_names[t]\n",
    "        model = utils.load_model(os.path.join(model_path, model_names[t]))\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        grdtruth = transform_tensor(Image.open(os.path.join(cst.DIR, TERMS[t],name_img)))\n",
    "        plt.imshow(grdtruth.squeeze())\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(save_path, save_name + \"_gt_\" + TERMS[t] + \".jpg\"))\n",
    "        plt.show()\n",
    "        grdtruth = grdtruth.unsqueeze(dim=0)\n",
    "        all_groundtruth.append(grdtruth)\n",
    "        \n",
    "        prediction = predict_img(model, transform(img), DEVICE, untransform, out_threshold=thresholds[t])\n",
    "        pred = torch.from_numpy(prediction)\n",
    "        all_predictions.append(pred)\n",
    "        plt.imshow(pred)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(save_path, save_name + \"_pred_\" + loss_name + \"_\"+ TERMS[t] + \".jpg\"))\n",
    "        plt.show()\n",
    "        \n",
    "    img_copy = img_copy * 255\n",
    "    img_copy = img_copy.type(torch.uint8)\n",
    "    img_copy2 = img_copy\n",
    "    \n",
    "    im = img_copy\n",
    "    im_gt = im\n",
    "    drawn_masks = []\n",
    "    for p in range(len(all_predictions)):\n",
    "            \n",
    "        predict = all_predictions[p]\n",
    "        predict = predict.unsqueeze(dim=0)\n",
    "        \n",
    "        gt = all_groundtruth[p].squeeze(dim=0)\n",
    "        gt_bool = gt > 0.9        \n",
    "        \n",
    "        im = draw_segmentation_masks(im, predict[0], alpha=1, colors=all_colors[p])\n",
    "        im_gt = draw_segmentation_masks(im_gt, gt_bool[0], alpha=1, colors=all_colors[p])\n",
    "        \n",
    "    plt.imshow(im.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(save_path, \"0_\" + save_name + \"_pred_on_img_\" + loss_name + \".jpg\"))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(im_gt.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(save_path, \"0_\" + save_name + \"_gt_on_img_\" + loss_name + \".jpg\"))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
