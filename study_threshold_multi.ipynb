{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00691c8",
   "metadata": {},
   "source": [
    "# Threshold study\n",
    "Evaluates the performances of the multi-class model (per annotation) for different threshold values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import os\n",
    "import random\n",
    "import datasets\n",
    "import metrics\n",
    "import time\n",
    "\n",
    "import constants as cst\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from unet import UNET\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4bafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(model, image, device, transform, out_threshold=0.5):\n",
    "    with torch.no_grad():\n",
    "        x = image\n",
    "        logits = model(x.to(device))\n",
    "        logits = transform(logits)\n",
    "        y_pred = nn.Softmax(dim=1)(logits)\n",
    "        y_size = y_pred.shape \n",
    "        proba = y_pred.detach().cpu().squeeze(0)\n",
    "        \n",
    "        all_out = []\n",
    "        for i in range(y_size[1]):\n",
    "            m = np.zeros((y_size[2], y_size[3]))\n",
    "            m = torch.where(proba[i,:,:]>out_threshold, 1,0)\n",
    "            all_out.append(m)\n",
    "        \n",
    "        all_out = tuple(all_out)\n",
    "        all_out = torch.stack(all_out, 0)\n",
    "    return all_out\n",
    "\n",
    "# Evaluate the performances for on threshold value\n",
    "def evaluate(eval_model, testing_loader, threshold):\n",
    "    tps = 0\n",
    "    precisions_br1 = []\n",
    "    recalls_br1 = []\n",
    "    F1s_br1 = []\n",
    "    IOUs_br1 = []\n",
    "    \n",
    "    precisions_br2 = []\n",
    "    recalls_br2 = []\n",
    "    F1s_br2 = []\n",
    "    IOUs_br2 = []\n",
    "    \n",
    "    precisions_cb = []\n",
    "    recalls_cb = []\n",
    "    F1s_cb = []\n",
    "    IOUs_cb = []\n",
    "    \n",
    "    precisions_ch = []\n",
    "    recalls_ch = []\n",
    "    F1s_ch = []\n",
    "    IOUs_ch = []\n",
    "    \n",
    "    precisions_cl = []\n",
    "    recalls_cl = []\n",
    "    F1s_cl = []\n",
    "    IOUs_cl = []\n",
    "    \n",
    "    precisions_d = []\n",
    "    recalls_d = []\n",
    "    F1s_d = []\n",
    "    IOUs_d = []\n",
    "    \n",
    "    precisions_en = []\n",
    "    recalls_en = []\n",
    "    F1s_en = []\n",
    "    IOUs_en = []\n",
    "    \n",
    "    precisions_hm = []\n",
    "    recalls_hm = []\n",
    "    F1s_hm = []\n",
    "    IOUs_hm = []\n",
    "    \n",
    "    precisions_m = []\n",
    "    recalls_m = []\n",
    "    F1s_m = []\n",
    "    IOUs_m = []\n",
    "    \n",
    "    precisions_n = []\n",
    "    recalls_n = []\n",
    "    F1s_n = []\n",
    "    IOUs_n = []\n",
    "    \n",
    "    precisions_oc = []\n",
    "    recalls_oc = []\n",
    "    F1s_oc = []\n",
    "    IOUs_oc = []\n",
    "    \n",
    "    precisions_op = []\n",
    "    recalls_op = []\n",
    "    F1s_op = []\n",
    "    IOUs_op = []\n",
    "    \n",
    "    precisions_p = []\n",
    "    recalls_p = []\n",
    "    F1s_p = []\n",
    "    IOUs_p = []\n",
    "    \n",
    "    precisions_vc = []\n",
    "    recalls_vc = []\n",
    "    F1s_vc = []\n",
    "    IOUs_vc = []\n",
    "\n",
    "    eval_model.eval()\n",
    "    for image, mask, name in testing_loader:\n",
    "        prediction = predict_img(eval_model, transform(image), DEVICE, untransform, threshold)\n",
    "        pred_masks = prediction\n",
    "\n",
    "        # One computation per mask, the threshold is studied per annotation and not globally\n",
    "        if mask[:,0,:,:].sum() > 0:\n",
    "            precisions_br1.append(metrics.precision(pred_masks[0,:,:], mask[:,0,:,:]))\n",
    "            recalls_br1.append(metrics.recall(pred_masks[0,:,:], mask[:,0,:,:]))\n",
    "            F1s_br1.append(metrics.F1Score(pred_masks[0,:,:], mask[:,0,:,:]))\n",
    "            IOUs_br1.append(metrics.IOUScore(pred_masks[0,:,:], mask[:,0,:,:]))\n",
    "\n",
    "        if mask[:,1,:,:].sum() > 0:\n",
    "            precisions_br2.append(metrics.precision(pred_masks[1,:,:], mask[:,1,:,:]))\n",
    "            recalls_br2.append(metrics.recall(pred_masks[1,:,:], mask[:,1,:,:]))\n",
    "            F1s_br2.append(metrics.F1Score(pred_masks[1,:,:], mask[:,1,:,:]))\n",
    "            IOUs_br2.append(metrics.IOUScore(pred_masks[1,:,:], mask[:,1,:,:]))\n",
    "\n",
    "        if mask[:,2,:,:].sum() > 0:\n",
    "            precisions_cb.append(metrics.precision(pred_masks[2,:,:], mask[:,2,:,:]))\n",
    "            recalls_cb.append(metrics.recall(pred_masks[2,:,:], mask[:,2,:,:]))\n",
    "            F1s_cb.append(metrics.F1Score(pred_masks[2,:,:], mask[:,2,:,:]))\n",
    "            IOUs_cb.append(metrics.IOUScore(pred_masks[2,:,:], mask[:,2,:,:]))\n",
    "\n",
    "        if mask[:,3,:,:].sum() > 0:\n",
    "            precisions_ch.append(metrics.precision(pred_masks[3,:,:], mask[:,3,:,:]))\n",
    "            recalls_ch.append(metrics.recall(pred_masks[3,:,:], mask[:,3,:,:]))\n",
    "            F1s_ch.append(metrics.F1Score(pred_masks[3,:,:], mask[:,3,:,:]))\n",
    "            IOUs_ch.append(metrics.IOUScore(pred_masks[3,:,:], mask[:,3,:,:]))\n",
    "\n",
    "        if mask[:,4,:,:].sum() > 0:\n",
    "            precisions_cl.append(metrics.precision(pred_masks[4,:,:], mask[:,4,:,:]))\n",
    "            recalls_cl.append(metrics.recall(pred_masks[4,:,:], mask[:,4,:,:]))\n",
    "            F1s_cl.append(metrics.F1Score(pred_masks[4,:,:], mask[:,4,:,:]))\n",
    "            IOUs_cl.append(metrics.IOUScore(pred_masks[4,:,:], mask[:,4,:,:]))\n",
    "\n",
    "        if mask[:,5,:,:].sum() > 0:\n",
    "            precisions_d.append(metrics.precision(pred_masks[5,:,:], mask[:,5,:,:]))\n",
    "            recalls_d.append(metrics.recall(pred_masks[5,:,:], mask[:,5,:,:]))\n",
    "            F1s_d.append(metrics.F1Score(pred_masks[5,:,:], mask[:,5,:,:]))\n",
    "            IOUs_d.append(metrics.IOUScore(pred_masks[5,:,:], mask[:,5,:,:]))\n",
    "\n",
    "        if mask[:,6,:,:].sum() > 0:\n",
    "            precisions_en.append(metrics.precision(pred_masks[6,:,:], mask[:,6,:,:]))\n",
    "            recalls_en.append(metrics.recall(pred_masks[6,:,:], mask[:,6,:,:]))\n",
    "            F1s_en.append(metrics.F1Score(pred_masks[6,:,:], mask[:,6,:,:]))\n",
    "            IOUs_en.append(metrics.IOUScore(pred_masks[6,:,:], mask[:,6,:,:]))\n",
    "\n",
    "        if mask[:,7,:,:].sum() > 0:\n",
    "            precisions_hm.append(metrics.precision(pred_masks[7,:,:], mask[:,7,:,:]))\n",
    "            recalls_hm.append(metrics.recall(pred_masks[7,:,:], mask[:,7,:,:]))\n",
    "            F1s_hm.append(metrics.F1Score(pred_masks[7,:,:], mask[:,7,:,:]))\n",
    "            IOUs_hm.append(metrics.IOUScore(pred_masks[7,:,:], mask[:,7,:,:]))\n",
    "\n",
    "        if mask[:,8,:,:].sum() > 0:\n",
    "            precisions_m.append(metrics.precision(pred_masks[8,:,:], mask[:,8,:,:]))\n",
    "            recalls_m.append(metrics.recall(pred_masks[8,:,:], mask[:,8,:,:]))\n",
    "            F1s_m.append(metrics.F1Score(pred_masks[8,:,:], mask[:,8,:,:]))\n",
    "            IOUs_m.append(metrics.IOUScore(pred_masks[8,:,:], mask[:,8,:,:]))\n",
    "\n",
    "        if mask[:,9,:,:].sum() > 0:\n",
    "            precisions_n.append(metrics.precision(pred_masks[9,:,:], mask[:,9,:,:]))\n",
    "            recalls_n.append(metrics.recall(pred_masks[9,:,:], mask[:,9,:,:]))\n",
    "            F1s_n.append(metrics.F1Score(pred_masks[9,:,:], mask[:,9,:,:]))\n",
    "            IOUs_n.append(metrics.IOUScore(pred_masks[9,:,:], mask[:,9,:,:]))\n",
    "\n",
    "        if mask[:,10,:,:].sum() > 0:\n",
    "            precisions_oc.append(metrics.precision(pred_masks[10,:,:], mask[:,10,:,:]))\n",
    "            recalls_oc.append(metrics.recall(pred_masks[10,:,:], mask[:,10,:,:]))\n",
    "            F1s_oc.append(metrics.F1Score(pred_masks[10,:,:], mask[:,10,:,:]))\n",
    "            IOUs_oc.append(metrics.IOUScore(pred_masks[10,:,:], mask[:,10,:,:]))\n",
    "\n",
    "        if mask[:,11,:,:].sum() > 0:\n",
    "            precisions_op.append(metrics.precision(pred_masks[11,:,:], mask[:,11,:,:]))\n",
    "            recalls_op.append(metrics.recall(pred_masks[11,:,:], mask[:,11,:,:]))\n",
    "            F1s_op.append(metrics.F1Score(pred_masks[11,:,:], mask[:,11,:,:]))\n",
    "            IOUs_op.append(metrics.IOUScore(pred_masks[11,:,:], mask[:,11,:,:]))\n",
    "\n",
    "        if mask[:,12,:,:].sum() > 0:\n",
    "            precisions_p.append(metrics.precision(pred_masks[12,:,:], mask[:,12,:,:]))\n",
    "            recalls_p.append(metrics.recall(pred_masks[12,:,:], mask[:,12,:,:]))\n",
    "            F1s_p.append(metrics.F1Score(pred_masks[12,:,:], mask[:,12,:,:]))\n",
    "            IOUs_p.append(metrics.IOUScore(pred_masks[12,:,:], mask[:,12,:,:]))\n",
    "\n",
    "        if mask[:,13,:,:].sum() > 0:\n",
    "            precisions_vc.append(metrics.precision(pred_masks[13,:,:], mask[:,13,:,:]))\n",
    "            recalls_vc.append(metrics.recall(pred_masks[13,:,:], mask[:,13,:,:]))\n",
    "            F1s_vc.append(metrics.F1Score(pred_masks[13,:,:], mask[:,13,:,:]))\n",
    "            IOUs_vc.append(metrics.IOUScore(pred_masks[13,:,:], mask[:,13,:,:]))\n",
    "            \n",
    "        precisions = [precisions_br1, precisions_br2, precisions_cb, precisions_ch, precisions_cl,\n",
    "                      precisions_d, precisions_en, precisions_hm, precisions_m, precisions_n,\n",
    "                      precisions_oc, precisions_op, precisions_p, precisions_vc]\n",
    "        recalls = [recalls_br1, recalls_br2, recalls_cb, recalls_ch, recalls_cl,\n",
    "                   recalls_d, recalls_en, recalls_hm, recalls_m, recalls_n,\n",
    "                   recalls_oc, recalls_op, recalls_p, recalls_vc]\n",
    "        F1s = [F1s_br1, F1s_br2, F1s_cb, F1s_ch, F1s_cl, F1s_d, F1s_en, F1s_hm, \n",
    "               F1s_m, F1s_n, F1s_oc, F1s_op, F1s_p, F1s_vc]\n",
    "        IOUs = [IOUs_br1, IOUs_br2, IOUs_cb, IOUs_ch, IOUs_cl, IOUs_d, IOUs_en,\n",
    "                IOUs_hm, IOUs_m, IOUs_n, IOUs_oc, IOUs_op, IOUs_p, IOUs_vc]\n",
    "    return precisions, recalls, F1s, IOUs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c39d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All fold models belonging to the same training run\n",
    "model_names = [\"alles_different_masks_CE_Fold_0_Epoch_59_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "          \"alles_different_masks_CE_Fold_1_Epoch_66_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "          \"alles_different_masks_CE_Fold_2_Epoch_56_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "          \"alles_different_masks_CE_Fold_3_Epoch_55_MaxEpochs_250_Adam_LR_0.0001.pth\",\n",
    "          \"alles_different_masks_CE_Fold_4_Epoch_96_MaxEpochs_250_Adam_LR_0.0001.pth\"]\n",
    "\n",
    "testing_set = datasets.ZebrafishDataset_multi(0,\n",
    "                                              dataset=\"test\",\n",
    "                                              folds=cst.FOLDS)\n",
    "\n",
    "testing_loader = torch.utils.data.DataLoader(testing_set,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=cst.WORKERS)\n",
    "\n",
    "SIZE = (384, 512)\n",
    "\n",
    "# Transforms for the images\n",
    "transform = transforms.Compose([transforms.Resize(SIZE),\n",
    "                                transforms.Pad((0, 64, 0, 64))])\n",
    "untransform = transforms.Compose([transforms.CenterCrop(SIZE),\n",
    "                                 transforms.Resize((1932, 2576))])\n",
    "\n",
    "n_th = 51\n",
    "loss_precision = [[0 for _ in range(n_th)] for _ in range(14)] # 14 is the number of annotations, specific to this project\n",
    "loss_recall = [[0 for _ in range(n_th)] for _ in range(14)]\n",
    "loss_f1 = [[0 for _ in range(n_th)] for _ in range(14)]\n",
    "loss_IOU = [[0 for _ in range(n_th)] for _ in range(14)]\n",
    "\n",
    "thresholds = np.linspace(0, 1, num=n_th)\n",
    "\n",
    "fold_validation = []\n",
    "fold_precision = []\n",
    "fold_recall = []\n",
    "fold_f1 = []\n",
    "fold_IOU = []\n",
    "\n",
    "DEVICE_NAME = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE_NAME = 'cuda:0'\n",
    "DEVICE = torch.device(DEVICE_NAME)\n",
    "\n",
    "TERM = \"multi_all\"\n",
    "dir_name = os.path.join(cst.DIR,\"all_different_masks\")\n",
    "loss_name = \"CE\"\n",
    "\n",
    "for model_name in model_names:\n",
    "    model_path = os.path.join(cst.DIR, \"alles_different_masks_normal\", model_name)\n",
    "    model = utils.load_model_all(model_path)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    for th in range(n_th):\n",
    "        precisions, recalls, F1s, IOUs = evaluate(model, testing_loader, (0.1 + th*2)/100)\n",
    "\n",
    "        for i in range(14):\n",
    "            mean_precision = np.mean(precisions[i])\n",
    "            mean_recall = np.mean(recalls[i])\n",
    "            mean_f1 = np.mean(F1s[i])\n",
    "            mean_IOU = np.mean(IOUs[i])\n",
    "\n",
    "            loss_precision[i][th] += mean_precision/5\n",
    "            loss_recall[i][th] += mean_recall/5\n",
    "            loss_f1[i][th] += mean_f1/5\n",
    "            loss_IOU[i][th] += mean_IOU/5\n",
    "            \n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(F1s)\n",
    "        mean_IOU = np.mean(IOUs)\n",
    "\n",
    "        if th == (n_th-1)/2:\n",
    "            fold_precision.append(mean_precision)\n",
    "            fold_recall.append(mean_recall)\n",
    "            fold_f1.append(mean_f1)\n",
    "            fold_IOU.append(mean_IOU)\n",
    "            \n",
    "all_f_prec = np.mean(fold_precision)\n",
    "all_f_rec = np.mean(fold_recall)\n",
    "all_f_f1 = np.mean(fold_f1)\n",
    "all_f_IOU = np.mean(fold_IOU)\n",
    "\n",
    "for i in range(14):\n",
    "    term = cst.COMBINED_TERM[i]\n",
    "    max_IOU = np.argmax(loss_IOU[i])\n",
    "    print(\"Max IOU:\", loss_IOU[i][max_IOU])\n",
    "    print(\"Threshold:\", thresholds[max_IOU])\n",
    "\n",
    "    print(\"Threshold maximising the IOU score: \" + str(thresholds[max_IOU]) )\n",
    "    print(\"Precision: \" + str(loss_precision[i][max_IOU]))\n",
    "    print(\"Recall: \" + str(loss_recall[i][max_IOU]) )\n",
    "    print(\"F1-Dice: \" + str(loss_f1[i][max_IOU]))\n",
    "    print(\"IOU: \" + str(loss_IOU[i][max_IOU]) )\n",
    "    \n",
    "    plt.plot(thresholds, loss_precision[i] , label=\"precision\", color=\"tab:orange\")\n",
    "    plt.plot(thresholds, loss_recall[i], label=\"recall\", color=\"tab:green\")\n",
    "    plt.plot(thresholds, loss_f1[i], label=\"F1\", color=\"tab:red\")\n",
    "    plt.plot(thresholds, loss_IOU[i], label=\"IOU\", color=\"tab:purple\")\n",
    "    plt.ylabel(\"Metrics\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.title(\"Term: \" + term + \", Loss: \" + loss_name)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(dir_name, term + \"_\" + loss_name + \"_Metric_curves.jpg\"))\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
