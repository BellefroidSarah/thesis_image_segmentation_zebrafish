{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b0c910",
   "metadata": {},
   "source": [
    "# Creating segmenation masks \n",
    "### Creating masks using the multi-class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef8db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import os\n",
    "import random\n",
    "import metrics\n",
    "import time\n",
    "\n",
    "import constants as cst\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "\n",
    "from unet import UNET\n",
    "import utils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cfa612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(model, image, device, transform, index, out_threshold=0.5):\n",
    "    with torch.no_grad():\n",
    "        x = image\n",
    "        logits = model(x.to(device))\n",
    "        logits = transform(logits)\n",
    "        y_pred = nn.Softmax(dim=1)(logits)\n",
    "        y_cur = y_pred[:,index,:,:]\n",
    "        proba = y_cur.detach().cpu().squeeze(0).numpy()\n",
    "        return proba > out_threshold\n",
    "\n",
    "TERMS = cst.COMBINED_TERM\n",
    "    \n",
    "# Images that belong to every testing set\n",
    "names = [\"120220_4xzoom_v_fish 16.jpg\",\n",
    "        \"120220_4xzoom_v2_fish 14.jpg\",\n",
    "        \"26022020 inx +- 4xzoom fish08 v3.jpg\",\n",
    "        \"26022020 inx +- 4xzoom fish11 v.jpg\",\n",
    "        \"120220_4xzoom_v_fish 01.jpg\",\n",
    "        \"120220_4xzoom_v_fish 09.jpg\",\n",
    "        \"120220_4xzoom_v1_fish 19.jpg\",\n",
    "        \"120220_4xzoom_v2_fish 15.jpg\",\n",
    "        \"120220_4xzoom_v2_fish 17.jpg\",\n",
    "        \"120220_4xzoom_v1_fish 23.jpg\",\n",
    "        \"120220_4xzoom_v2_fish 21.jpg\",\n",
    "        \"120220_4xzoom_v1_fish 11.jpg\"]\n",
    "\n",
    "img_names = [\"img1\",\n",
    "             \"img2\",\n",
    "             \"img3\",\n",
    "             \"img4\",\n",
    "             \"img5\",\n",
    "             \"img6\",\n",
    "             \"img7\",\n",
    "             \"img8\",\n",
    "             \"img9\",\n",
    "             \"img10\",\n",
    "             \"img11\",\n",
    "             \"img12\"]\n",
    "\n",
    "random.seed(cst.SEED)\n",
    "torch.manual_seed(cst.SEED)\n",
    "np.random.seed(cst.SEED)\n",
    "\n",
    "# Model \n",
    "model_names = [\"alles_different_masks_Focal_Fold_2_Epoch_43_MaxEpochs_250_Adam_LR_0.0001.pth\"]\n",
    "\n",
    "\n",
    "model_path = os.path.join(cst.DIR, \"final_multi\")\n",
    "save_path = os.path.join(cst.DIR, \"pred_multi_focal\")\n",
    "\n",
    "# Threshold for each annotation\n",
    "thresholds = [0.96,\n",
    "              0.88,\n",
    "              0.42,\n",
    "              0.8,\n",
    "              0.44,\n",
    "              0.92,\n",
    "              0.86,\n",
    "              0.88,\n",
    "              0.78,\n",
    "              0.48,\n",
    "              0.44,\n",
    "              0.9,\n",
    "              0.94,\n",
    "              0.96]\n",
    "\n",
    "# One color for each annotation\n",
    "all_colors = [\"red\",\n",
    "          \"coral\",\n",
    "          \"sandybrown\",\n",
    "          \"gold\",\n",
    "          \"greenyellow\",\n",
    "          \"seagreen\",\n",
    "          \"cyan\",\n",
    "          \"steelblue\",\n",
    "          \"blue\",\n",
    "          \"mediumslateblue\",\n",
    "          \"darkorchid\",\n",
    "          \"magenta\",\n",
    "          \"lightpink\",\n",
    "          \"dimgrey\"]\n",
    "\n",
    "loss_name = \"Focal\"\n",
    "fold = 0\n",
    "\n",
    "SIZE = (384, 512)\n",
    "\n",
    "\n",
    "DEVICE_NAME = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE_NAME = 'cuda:0'\n",
    "DEVICE = torch.device(DEVICE_NAME)\n",
    "\n",
    "transform_tensor = transforms.ToTensor()\n",
    "transform = transforms.Compose([transforms.Resize(SIZE),\n",
    "                                transforms.Pad((0, 64, 0, 64))])\n",
    "untransform = transforms.Compose([transforms.CenterCrop(SIZE),\n",
    "                                 transforms.Resize((1932, 2576))])\n",
    "\n",
    "for i in range(len(names)):\n",
    "    name_img = names[i]\n",
    "    save_name = img_names[i]\n",
    "    \n",
    "    img_path = os.path.join(cst.DIR, \"images\")\n",
    "    \n",
    "    img = transform_tensor(Image.open(os.path.join(img_path, name_img)))\n",
    "    img = img[:3,:,:]\n",
    "    img_copy = img\n",
    "    img = img.unsqueeze(dim=0)\n",
    "    \n",
    "    all_groundtruth = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    for t in range(len(TERMS)):\n",
    "        print(\"Image:\" , name_img)\n",
    "        print(\"Model:\", model_names[0])\n",
    "        print(\"Threshold:\", thresholds[t])\n",
    "        model_name = model_names[0]\n",
    "        model = utils.load_model_all(os.path.join(model_path, model_names[0]))\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        grdtruth = transform_tensor(Image.open(os.path.join(cst.DIR, TERMS[t],name_img)))\n",
    "        plt.imshow(grdtruth.squeeze())\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(save_path, save_name + \"_gt_\" + TERMS[t] + \".jpg\"))\n",
    "        plt.show()\n",
    "        grdtruth = grdtruth.unsqueeze(dim=0)\n",
    "        all_groundtruth.append(grdtruth)\n",
    "        \n",
    "        prediction = predict_img(model, transform(img), DEVICE, untransform, t, out_threshold=thresholds[t])\n",
    "        pred = torch.from_numpy(prediction)\n",
    "        all_predictions.append(pred)\n",
    "        plt.imshow(pred)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(save_path, save_name + \"_pred_\" + loss_name + \"_\"+ TERMS[t] + \".jpg\"))\n",
    "        plt.show()\n",
    "        \n",
    "    img_copy = img_copy * 255\n",
    "    img_copy = img_copy.type(torch.uint8)\n",
    "    img_copy2 = img_copy\n",
    "    \n",
    "    im = img_copy\n",
    "    im_gt = im\n",
    "    drawn_masks = []\n",
    "    for p in range(len(all_predictions)):\n",
    "            \n",
    "        predict = all_predictions[p]\n",
    "        predict = predict.unsqueeze(dim=0)\n",
    "        \n",
    "        gt = all_groundtruth[p].squeeze(dim=0)\n",
    "        gt_bool = gt > 0.9        \n",
    "        \n",
    "        im = draw_segmentation_masks(im, predict[0], alpha=1, colors=all_colors[p])\n",
    "        im_gt = draw_segmentation_masks(im_gt, gt_bool[0], alpha=1, colors=all_colors[p])\n",
    "        \n",
    "    plt.imshow(im.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(save_path, \"0_\" + save_name + \"_pred_on_img_\" + loss_name + \".jpg\"))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(im_gt.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(save_path, \"0_\" + save_name + \"_gt_on_img_\" + loss_name + \".jpg\"))\n",
    "    plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
