{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9aee86",
   "metadata": {},
   "source": [
    "# Train - Validate - Evaluate - Threshold study\n",
    "This notebook focuses on the binary model. At the end of training the model performances are computed for multiple threshold values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c257a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import os\n",
    "import random\n",
    "import datasets\n",
    "import metrics\n",
    "import time\n",
    "\n",
    "import constants as cst\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchgeometry.losses as loss_fn\n",
    "from unet import UNET\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(model, image, device, transform, out_threshold=0.5):\n",
    "    with torch.no_grad():\n",
    "        x = image\n",
    "        logits = model(x.to(device))\n",
    "        logits = transform(logits)\n",
    "        y_pred = nn.Softmax(dim=1)(logits)\n",
    "        proba = y_pred.detach().cpu().squeeze(0).numpy()[1, :, :]\n",
    "        return proba > out_threshold\n",
    "\n",
    "# One validation step\n",
    "def validate(model, validation_loader, transform, DEVICE):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = []\n",
    "        for images, masks, names in validation_loader:\n",
    "            images = transform(images)\n",
    "            outputs = model(images.to(DEVICE))\n",
    "\n",
    "            masks = masks.type(torch.LongTensor)\n",
    "            masks = transform(masks)\n",
    "            masks = torch.squeeze(masks, 1)\n",
    "\n",
    "            vloss = criterion(outputs, masks.to(DEVICE))\n",
    "            loss = vloss.detach().item()\n",
    "            val_loss.append(loss)\n",
    "\n",
    "        loss = np.mean(val_loss)\n",
    "    return loss\n",
    "\n",
    "# One training step\n",
    "def train(model, training_loader, transforms, DEVICE, criterion, optimiser):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for images, masks, names in training_loader:\n",
    "        images = transform(images)\n",
    "        outputs = model(images.to(DEVICE))\n",
    "\n",
    "        masks = masks.type(torch.LongTensor)\n",
    "        masks = transform(masks)\n",
    "        masks = torch.squeeze(masks, 1)\n",
    "\n",
    "        tloss = criterion(outputs, masks.to(DEVICE))\n",
    "        loss = tloss.detach().item()\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        tloss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    loss = np.mean(train_loss)\n",
    "    return loss\n",
    "\n",
    "# Evaluating the performances of the model for a certain threshold value\n",
    "def evaluate(eval_model, testing_loader, threshold):\n",
    "    tps = 0\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    F1s = []\n",
    "    IOUs = []\n",
    "\n",
    "    eval_model.eval()\n",
    "    for image, mask, name in testing_loader:\n",
    "        prediction = predict_img(eval_model, transform(image), DEVICE, untransform, out_threshold=threshold)\n",
    "        pred = torch.from_numpy(prediction)\n",
    "\n",
    "        precisions.append(metrics.precision(pred, mask))\n",
    "        recalls.append(metrics.recall(pred, mask))\n",
    "        F1s.append(metrics.F1Score(pred, mask))\n",
    "        IOUs.append(metrics.IOUScore(pred, mask))\n",
    "    return precisions, recalls, F1s, IOUs\n",
    "\n",
    "# Writes the performances of the model with a threshold of 0.5 to a text file \n",
    "# Writes it in a latex table format\n",
    "def write_latex_half(dir_name, loss_name, val, prec, rec, f1, IOU):\n",
    "    f = open(os.path.join(dir_name,\"latex_half.txt\"),\"a+\")\n",
    "    if loss_name == \"CE\":\n",
    "        f.write(\"\\\\begin{table}[!h]\\n\")\n",
    "        f.write(\"\\\\centering\\n\")\n",
    "        f.write(\"\\\\begin{tabular}{|c|c|c|c|c|c|c|}\\n\")\n",
    "        f.write(\"\\\\hline\\n\")\n",
    "        f.write(\"Loss & Validation & Precision & Recall & F1 & IOU & Avg\\\\\\\\ \\n\")\n",
    "        f.write(\"\\\\hline\\n\")\n",
    "        f.write(\"\\\\hline\\n\")\n",
    "    f.write(loss_name + \" & \" + str(val) + \" & \" + str(prec) + \" & \" + str(rec)\n",
    "            + \" & \" + str(f1) + \" & \" + str(IOU) + \" & \" + str((prec+rec+f1+IOU)/4) + \"\\\\\\\\ \\n\")\n",
    "    f.write(\"\\\\hline\\n\")\n",
    "    if loss_name == \"Focal\":\n",
    "        f.write(\"\\end{tabular}\\n\")\n",
    "        f.write(\"\\\\caption{}\\n\")\n",
    "        f.write(\"\\\\label{}\\n\")\n",
    "        f.write(\"\\\\end{table}\\n\")\n",
    "    f.close()\n",
    "    return\n",
    "\n",
    "# Writes the performances of the model with a threshold maximizing the IOU to a text file \n",
    "# Writes it in a latex table format\n",
    "def write_latex_IOU(dir_name, loss_name, prec, rec, f1, IOU, th):\n",
    "    f = open(os.path.join(dir_name,\"latex_max_IOU.txt\"),\"a+\")\n",
    "    if loss_name == \"CE\":\n",
    "        f.write(\"\\\\begin{table}[!h]\\n\")\n",
    "        f.write(\"\\\\centering\\n\")\n",
    "        f.write(\"\\\\begin{tabular}{|c|c|c|c|c|c|c|}\\n\")\n",
    "        f.write(\"\\\\hline\\n\")\n",
    "        f.write(\"Loss & Threshold & Precision & Recall & F1 & IOU & Avg\\\\\\\\ \\n\")\n",
    "        f.write(\"\\\\hline\\n\")\n",
    "        f.write(\"\\\\hline\\n\")\n",
    "    f.write(loss_name + \" & \" + str(th) + \" & \" + str(prec) + \" & \" + str(rec)\n",
    "            + \" & \" + str(f1) + \" & \" + str(IOU) + \" & \" + str((prec+rec+f1+IOU)/4) + \"\\\\\\\\ \\n\")\n",
    "    f.write(\"\\\\hline\\n\")\n",
    "    if loss_name == \"Focal\":\n",
    "        f.write(\"\\\\end{tabular}\\n\")\n",
    "        f.write(\"\\\\caption{}\\n\")\n",
    "        f.write(\"\\\\label{}\\n\")\n",
    "        f.write(\"\\\\end{table}\\n\")\n",
    "    f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(cst.SEED)\n",
    "torch.manual_seed(cst.SEED)\n",
    "np.random.seed(cst.SEED)\n",
    "\n",
    "TERM = \"br2\"  # Term to segment\n",
    "SIZE = (384, 512)  # Related to this project\n",
    "FOLDS = [0,1,2,3,4]  # Allows to run all or some folds (computational resources limits)\n",
    "LOSSES = [\"CE\", \"Dice\", \"Tversky\", \"Focal\"] # Can study all or some loss functions (computational resources limits)\n",
    "n_th = 51\n",
    "thresholds = np.linspace(0, 1, num=n_th)  # All threshold values used to study the performances\n",
    "\n",
    "run_name = TERM + \"_normal\"\n",
    "dir_name = os.path.join(cst.DIR, run_name)\n",
    "os.makedirs(dir_name, exist_ok = True)\n",
    "\n",
    "# Text file log\n",
    "if \"train.txt\" not in os.listdir(dir_name):\n",
    "    f = open(os.path.join(dir_name,\"train.txt\"),\"w+\")\n",
    "    f.write(\"--------------------------------------------------\\n\")\n",
    "    f.write(\"Term studied: \" + TERM + \"\\n\\n\")\n",
    "    f.write(\"--------------------------------------------------\\n\")\n",
    "    f.close()\n",
    "\n",
    "DEVICE_NAME = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE_NAME = 'cuda:0'\n",
    "DEVICE = torch.device(DEVICE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e9cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loss_name in LOSSES:\n",
    "    print(\"Starting loss:\", loss_name)\n",
    "    # Used for studying the performances using different threshold values\n",
    "    loss_precision = [0] * n_th\n",
    "    loss_recall = [0] * n_th\n",
    "    loss_f1 = [0] * n_th\n",
    "    loss_IOU = [0] * n_th\n",
    "    \n",
    "    print(\"Starting term: \" + TERM)\n",
    "    start_term = time.time()\n",
    "\n",
    "    image_folder = os.path.join(cst.DIR, \"images\")\n",
    "    mask_folder = os.path.join(cst.DIR, TERM)\n",
    "\n",
    "    # Transforms for the images\n",
    "    transform = transforms.Compose([transforms.Resize(SIZE),\n",
    "                                    transforms.Pad((0, 64, 0, 64))])\n",
    "    untransform = transforms.Compose([transforms.CenterCrop(SIZE),\n",
    "                                     transforms.Resize((1932, 2576))])\n",
    "\n",
    "    fold_validation = []\n",
    "    fold_precision = []\n",
    "    fold_recall = []\n",
    "    fold_f1 = []\n",
    "    fold_IOU = []\n",
    "\n",
    "    for fold in FOLDS:\n",
    "        print(\"Starting fold: {}\".format(fold))\n",
    "        start_fold = time.time()\n",
    "        \"\"\"Datasets and loaders\"\"\"\n",
    "        training_set = datasets.ZebrafishDataset_KFold(image_folder,\n",
    "                                                      mask_folder,\n",
    "                                                      actual_fold=fold,\n",
    "                                                      dataset=\"train\",\n",
    "                                                      folds=cst.FOLDS)\n",
    "        validation_set = datasets.ZebrafishDataset_KFold(image_folder,\n",
    "                                                        mask_folder,\n",
    "                                                        actual_fold=fold,\n",
    "                                                        dataset=\"validate\",\n",
    "                                                        folds=cst.FOLDS)\n",
    "        testing_set = datasets.ZebrafishDataset_KFold(image_folder,\n",
    "                                                     mask_folder,\n",
    "                                                     actual_fold=fold,\n",
    "                                                     dataset=\"test\",\n",
    "                                                     folds=cst.FOLDS)\n",
    "\n",
    "        training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                                      batch_size=cst.BATCH_SIZE,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=cst.WORKERS)\n",
    "\n",
    "        validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                        batch_size=cst.BATCH_SIZE,\n",
    "                                                        shuffle=True,\n",
    "                                                        num_workers=cst.WORKERS)\n",
    "\n",
    "        testing_loader = torch.utils.data.DataLoader(testing_set,\n",
    "                                                     batch_size=1,\n",
    "                                                     shuffle=True,\n",
    "                                                     num_workers=cst.WORKERS)\n",
    "\n",
    "        model = UNET(3, 2)\n",
    "        model.to(DEVICE)\n",
    "        best_model = UNET(3, 2)\n",
    "        best_model = model\n",
    "       \n",
    "        # Text file log - writing loss and parameters\n",
    "        f = open(os.path.join(dir_name,\"train.txt\"),\"a+\")\n",
    "        if fold==0:\n",
    "            f.write(\"Loss used: \" + loss_name + \"\\n\\n\")\n",
    "                \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        criterion_string = loss_name\n",
    "\n",
    "        if loss_name == \"Dice\":\n",
    "            criterion = loss_fn.DiceLoss()\n",
    "        if loss_name == \"Loss used: Tversky\":\n",
    "            A = 0.7\n",
    "            B = 0.3\n",
    "            criterion = loss_fn.TverskyLoss(alpha=A, beta=B)\n",
    "            if fold==0:\n",
    "                f.write(\"Alpha: \" + str(A) + \"\\n\")\n",
    "                f.write(\"Beta: \" + str(B) + \"\\n\\n\")\n",
    "        if loss_name == \"Focal\":\n",
    "            A = 0.8\n",
    "            G = 2\n",
    "            criterion = loss_fn.FocalLoss(alpha=A, gamma=G, reduction=\"mean\")\n",
    "            if fold==0:\n",
    "                f.write(\"Alpha: \" + str(A) + \"\\n\")\n",
    "                f.write(\"Gamma: \" + str(G) + \"\\n\\n\")\n",
    "            \n",
    "        if fold==0:\n",
    "            f.write(\"Learning rate: \" + str(cst.LEARNING_RATE) + \"\\n\")\n",
    "            f.write(\"Weight decay: \" + str(cst.WEIGHT_DECAY) + \"\\n\")\n",
    "            f.write(\"Max epochs: \" + str(cst.EPOCHS) + \"\\n\")\n",
    "            f.write(\"Batch size: \" + str(cst.BATCH_SIZE) + \"\\n\")\n",
    "            f.write(\"Workers: \" + str(cst.WORKERS) + \"\\n\\n\")\n",
    "            f.write(\"--------------------------------------------------\\n\")\n",
    "        f.write(\"Current fold: \" + str(fold) + \"\\n\\n\")\n",
    "        f.close()\n",
    "\n",
    "        optimiser = torch.optim.Adam(model.parameters(), lr=cst.LEARNING_RATE, weight_decay=cst.WEIGHT_DECAY)\n",
    "\n",
    "        \"\"\"Computing validation loss before training\"\"\"\n",
    "        loss = validate(model, validation_loader, transform, DEVICE)\n",
    "\n",
    "        best_val = loss\n",
    "        best_epoch = 0\n",
    "        last_epoch = 0\n",
    "\n",
    "        epochs_train_losses = []\n",
    "        epochs_val_losses = []\n",
    "        for epoch in range(cst.EPOCHS):\n",
    "            \"\"\"Training\"\"\"\n",
    "            loss = train(model, training_loader, transforms, DEVICE, criterion, optimiser)\n",
    "            epochs_train_losses.append(loss)\n",
    "\n",
    "            \"\"\"Validation\"\"\"\n",
    "            loss = validate(model, validation_loader, transform, DEVICE)\n",
    "            epochs_val_losses.append(loss)\n",
    "\n",
    "            \"\"\"Updating best model\"\"\"\n",
    "            if loss < best_val:\n",
    "                best_val = loss\n",
    "                best_model = model\n",
    "                best_epoch = epoch+1\n",
    "\n",
    "            if (epoch+1)%50 == 0:\n",
    "                print(\"Epoch: \" + str(epoch+1))\n",
    "                print(\"Validation: {}.\".format(loss))\n",
    "                print(\"Best validation: {}.\".format(best_val))\n",
    "\n",
    "            \"\"\"Train and validate loops over\"\"\"\n",
    "            curr = time.time()\n",
    "            curr = curr - start_term\n",
    "            secondes = curr % 60\n",
    "            minutes = (curr-secondes)/60\n",
    "\n",
    "            last_epoch = epoch\n",
    "\n",
    "            # Notebooks shutdown after 6 hours. Stop the code and save the results.\n",
    "            if minutes >= 345:\n",
    "                f = open(os.path.join(dir_name,\"train.txt\"),\"a+\")\n",
    "                f.write(\"Learning stopped due to timeout. \\n\")\n",
    "                f.close()\n",
    "                break\n",
    "            if (epoch - best_epoch) >= 50:\n",
    "                break\n",
    "\n",
    "        \"\"\"All epochs are over\"\"\"\n",
    "        fold_validation.append(best_val)\n",
    "\n",
    "        model_name = TERM + '_' + loss_name + \"_Fold_\" + str(fold) + \"_Epoch_\" + str(best_epoch) + \"_MaxEpochs_\" \n",
    "        model_name += str(cst.EPOCHS) + '_' + cst.OPTIMIZER + \"_LR_\" + str(cst.LEARNING_RATE) + \".pth\"\n",
    "\n",
    "        model_filepath = os.path.join(dir_name, model_name)\n",
    "        torch.save(best_model.state_dict(), model_filepath) # save better?\n",
    "        \n",
    "        curr = time.time()\n",
    "        curr = curr - start_fold\n",
    "        secondes = curr % 60\n",
    "        minutes = (curr-secondes)/60\n",
    "\n",
    "        # Plot losses\n",
    "        index = [i+1 for i in range(last_epoch+1)]\n",
    "        plt.plot(index[1:], epochs_train_losses[1:], label=\"Training\")\n",
    "        plt.plot(index[1:], epochs_val_losses[1:], label=\"Validation\")\n",
    "        plt.title(\"Term: \" + TERM + \", Loss: \" + loss_name + \", Fold: \" + str(fold)) \n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(dir_name, TERM + \"_\" + loss_name +\"_Fold_\" + str(fold) + \"_Loss_curves.jpg\"))\n",
    "        plt.show()\n",
    "        \n",
    "        # Text file log\n",
    "        f = open(os.path.join(dir_name,\"train.txt\"),\"a+\")\n",
    "        f.write(\"Best epoch: \" + str(best_epoch) + \"\\n\")\n",
    "        f.write(\"Best validation loss: \" + str(best_val) + \"\\n\")\n",
    "        f.write(\"Ellapsed time: \" + str(minutes) + \" minutes \" + str(secondes) + \" seconds\\n\\n\")\n",
    "        f.write(\"Name of the model saved:\\n\")\n",
    "        f.write(model_name + \"\\n\\n\")\n",
    "        f.close()\n",
    "\n",
    "        \"\"\"Evaluating performances for each threshold\"\"\"\n",
    "        for th in range(n_th):\n",
    "            precisions, recalls, F1s, IOUs = evaluate(best_model, testing_loader, (th*2)/100)\n",
    "\n",
    "            mean_precision = np.mean(precisions)\n",
    "            mean_recall = np.mean(recalls)\n",
    "            mean_f1 = np.mean(F1s)\n",
    "            mean_IOU = np.mean(IOUs)\n",
    "\n",
    "            loss_precision[th] += mean_precision\n",
    "            loss_recall[th] += mean_recall\n",
    "            loss_f1[th] += mean_f1\n",
    "            loss_IOU[th] += mean_IOU\n",
    "\n",
    "            # Text file log - perfomances with a threshold of 0.5\n",
    "            if th == (n_th-1)/2:\n",
    "                f = open(os.path.join(dir_name,\"train.txt\"),\"a+\")\n",
    "                f.write(\"Performance of this model for a threshold of 0.5: \\n\")\n",
    "                f.write(\"Precision: \" + str(mean_precision) + \"\\n\")\n",
    "                f.write(\"Recall: \" + str(mean_recall) + \"\\n\")\n",
    "                f.write(\"F1-Dice: \" + str(mean_f1) + \"\\n\")\n",
    "                f.write(\"IOU: \" + str(mean_IOU) + \"\\n\")\n",
    "                f.write(\"Average: \" + str((mean_precision+mean_recall+mean_f1+mean_IOU)/4)+ \"\\n\")\n",
    "                f.close()\n",
    "                fold_precision.append(mean_precision)\n",
    "                fold_recall.append(mean_recall)\n",
    "                fold_f1.append(mean_f1)\n",
    "                fold_IOU.append(mean_IOU)\n",
    "\n",
    "        confidence = 0.9\n",
    "        \n",
    "        curr = time.time()\n",
    "        curr = curr - start_fold\n",
    "        secondes = curr % 60\n",
    "        minutes = (curr-secondes)/60\n",
    "        f = open(os.path.join(dir_name,\"train.txt\"),\"a+\")\n",
    "        f.write(\"Total fold time: \" + str(minutes) + \" minutes \" + str(secondes) + \" seconds\\n\\n\")\n",
    "        f.write(\"--------------------------------------------------\\n\")\n",
    "\n",
    "        print(\"Last epoch: {}\".format(last_epoch))\n",
    "        print(\"Term: \" + TERM)\n",
    "        print(\"Fold: {}\".format(fold))\n",
    "        print(\"Fold took: \" + str(minutes) + \" minutes \" + str(secondes) + \" seconds to train\")\n",
    "        print(\"Last val: {}\".format(loss))\n",
    "        print(\"Best val: {}\".format(best_val))\n",
    "        print()\n",
    "        print(\"Precision: {}\".format(fold_precision[fold]))\n",
    "        print(\"Recall: {}\".format(fold_recall[fold]))\n",
    "        print(\"F1/Dice score: {}\".format(fold_f1[fold]))\n",
    "        print(\"IoU: {}\".format(fold_IOU[fold]))\n",
    "        avg = (fold_precision[fold]+ fold_recall[fold]+ fold_f1[fold]+fold_IOU[fold])/4\n",
    "        print(\"Avg:\", avg)\n",
    "        print(\"--------------------\")\n",
    "    \"\"\"Fold loop end\"\"\"\n",
    "    \n",
    "    # Mean performances of all folds\n",
    "    all_f_prec = np.mean(fold_precision)\n",
    "    all_f_rec = np.mean(fold_recall)\n",
    "    all_f_f1 = np.mean(fold_f1)\n",
    "    all_f_IOU = np.mean(fold_IOU)\n",
    "    all_f_val = str(np.mean(fold_validation))\n",
    "    \n",
    "    # Text file log - mean performmances\n",
    "    f = open(os.path.join(dir_name,\"train.txt\"),\"a+\")\n",
    "    f.write(\"Average performance of all models for a threshold of 0.5: \\n\")\n",
    "    f.write(\"Mean validation: \" + str(all_f_val) + \"\\n\")\n",
    "    f.write(\"Precision: \" + str(all_f_prec) + \"\\n\")\n",
    "    f.write(\"Recall: \" + str(all_f_rec) + \"\\n\")\n",
    "    f.write(\"F1-Dice: \" + str(all_f_f1) + \"\\n\")\n",
    "    f.write(\"IOU: \" + str(all_f_IOU) + \"\\n\")\n",
    "    f.write(\"Average: \" + str((all_f_prec+all_f_rec+all_f_f1+all_f_IOU)/4) + \"\\n\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    write_latex_half(dir_name, loss_name, all_f_val, all_f_prec, all_f_rec, all_f_f1, all_f_IOU)\n",
    "    \n",
    "    # Average of all performances for all threshold values\n",
    "    loss_avg = [0] * n_th\n",
    "    for i in range(len(loss_precision)):\n",
    "        loss_precision[i] = loss_precision[i]/5\n",
    "        loss_recall[i] = loss_recall[i]/5\n",
    "        loss_f1[i] = loss_f1[i]/5\n",
    "        loss_IOU[i] = loss_IOU[i]/5\n",
    "        loss_avg[i] = (loss_precision[i]+loss_recall[i]+loss_f1[i]+loss_IOU[i])/4\n",
    "    \n",
    "    # Studying threshold maximizing each metric\n",
    "    max_IOU = np.argmax(loss_IOU)\n",
    "    max_prec = np.argmax(loss_precision)\n",
    "    max_rec = np.argmax(loss_recall)\n",
    "    max_f1 = np.argmax(loss_f1)\n",
    "    max_avg = np.argmax(loss_avg)\n",
    "    \n",
    "    # Text file log - maximum precision\n",
    "    f = open(os.path.join(dir_name,\"train.txt\"),\"a+\")\n",
    "    f.write(\"Threshold maximising the precision: \" + str(thresholds[max_prec]) + \"\\n\")\n",
    "    f.write(\"Precision: \" + str(loss_precision[max_prec]) + \"\\n\")\n",
    "    f.write(\"Recall: \" + str(loss_recall[max_prec]) + \"\\n\")\n",
    "    f.write(\"F1-Dice: \" + str(loss_f1[max_prec]) + \"\\n\")\n",
    "    f.write(\"IOU: \" + str(loss_IOU[max_prec]) + \"\\n\")\n",
    "    f.write(\"Average: \" + str(loss_avg[max_prec]) + \"\\n\\n\")\n",
    "    \n",
    "    # Text file log - maximum recall\n",
    "    f.write(\"Threshold maximising the recall: \" + str(thresholds[max_rec]) + \"\\n\")\n",
    "    f.write(\"Precision: \" + str(loss_precision[max_rec]) + \"\\n\")\n",
    "    f.write(\"Recall: \" + str(loss_recall[max_rec]) + \"\\n\")\n",
    "    f.write(\"F1-Dice: \" + str(loss_f1[max_rec]) + \"\\n\")\n",
    "    f.write(\"IOU: \" + str(loss_IOU[max_rec]) + \"\\n\")\n",
    "    f.write(\"Average: \" + str(loss_avg[max_rec]) + \"\\n\\n\")\n",
    "    \n",
    "    # Text file log - maximum Dice score\n",
    "    f.write(\"Threshold maximising the F1-Dice score: \" + str(thresholds[max_f1]) + \"\\n\")\n",
    "    f.write(\"Precision: \" + str(loss_precision[max_f1]) + \"\\n\")\n",
    "    f.write(\"Recall: \" + str(loss_recall[max_f1]) + \"\\n\")\n",
    "    f.write(\"F1-Dice: \" + str(loss_f1[max_f1]) + \"\\n\")\n",
    "    f.write(\"IOU: \" + str(loss_IOU[max_f1]) + \"\\n\")\n",
    "    f.write(\"Average: \" + str(loss_avg[max_f1]) + \"\\n\\n\")\n",
    "    \n",
    "    # Text file log - maximum IOU\n",
    "    f.write(\"Threshold maximising the IOU score: \" + str(thresholds[max_IOU]) + \"\\n\")\n",
    "    f.write(\"Precision: \" + str(loss_precision[max_IOU]) + \"\\n\")\n",
    "    f.write(\"Recall: \" + str(loss_recall[max_IOU]) + \"\\n\")\n",
    "    f.write(\"F1-Dice: \" + str(loss_f1[max_IOU]) + \"\\n\")\n",
    "    f.write(\"IOU: \" + str(loss_IOU[max_IOU]) + \"\\n\")\n",
    "    f.write(\"Average: \" + str(loss_avg[max_IOU]) + \"\\n\\n\")\n",
    "    \n",
    "    # Text file log - maximum average\n",
    "    f.write(\"Threshold maximising the average performances: \" + str(thresholds[max_avg]) + \"\\n\")\n",
    "    f.write(\"Precision: \" + str(loss_precision[max_avg]) + \"\\n\")\n",
    "    f.write(\"Recall: \" + str(loss_recall[max_avg]) + \"\\n\")\n",
    "    f.write(\"F1-Dice: \" + str(loss_f1[max_avg]) + \"\\n\")\n",
    "    f.write(\"IOU: \" + str(loss_IOU[max_avg]) + \"\\n\")\n",
    "    f.write(\"Average: \" + str(loss_avg[max_avg]) + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"--------------------------------------------------\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    write_latex_IOU(dir_name,\n",
    "                    loss_name, \n",
    "                    loss_precision[max_IOU], \n",
    "                    loss_recall[max_IOU], \n",
    "                    loss_f1[max_IOU], \n",
    "                    loss_IOU[max_IOU], \n",
    "                    thresholds[max_IOU])\n",
    "    \n",
    "    # Plot - all metric curves\n",
    "    plt.plot(thresholds, loss_avg , label=\"average\", color=\"tab:blue\")\n",
    "    plt.plot(thresholds, loss_precision , label=\"precision\", color=\"tab:orange\")\n",
    "    plt.plot(thresholds, loss_recall, label=\"recall\", color=\"tab:green\")\n",
    "    plt.plot(thresholds, loss_f1, label=\"F1\", color=\"tab:red\")\n",
    "    plt.plot(thresholds, loss_IOU, label=\"IOU\", color=\"tab:purple\")\n",
    "    plt.ylabel(\"Metrics\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.title(\"Term: \" + TERM + \", Loss: \" + loss_name)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(dir_name, TERM + \"_\" + loss_name + \"_Metric_curves.jpg\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot - average curve\n",
    "    plt.plot(thresholds, loss_avg , label=\"average\", color=\"tab:blue\")\n",
    "    plt.vlines(thresholds[max_avg], 0, loss_avg[max_avg], colors=\"black\",linestyles=\"dashed\")\n",
    "    plt.hlines(loss_avg[max_avg], 0, thresholds[max_avg], colors=\"black\",linestyles=\"dashed\")\n",
    "    plt.ylabel(\"Average\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.title(\"Term: \" + TERM + \", Loss: \" + loss_name)\n",
    "    plt.savefig(os.path.join(dir_name, TERM + \"_\" + loss_name + \"_Average_curve.jpg\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot - precision curve\n",
    "    plt.plot(thresholds, loss_precision , label=\"precision\", color=\"tab:orange\")\n",
    "    plt.vlines(thresholds[max_prec], 0, loss_precision[max_prec], colors=\"black\",linestyles=\"dashed\")\n",
    "    plt.hlines(loss_precision[max_prec], 0, thresholds[max_prec], colors=\"black\",linestyles=\"dashed\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.title(\"Term: \" + TERM + \", Loss: \" + loss_name)\n",
    "    plt.savefig(os.path.join(dir_name, TERM + \"_\" + loss_name + \"_Precision_curve.jpg\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot - recall curve\n",
    "    plt.plot(thresholds, loss_recall , label=\"recall\", color=\"tab:green\")\n",
    "    plt.vlines(thresholds[max_rec], 0, loss_recall[max_rec], colors=\"black\",linestyles=\"dashed\")\n",
    "    plt.hlines(loss_recall[max_rec], 0, thresholds[max_rec], colors=\"black\",linestyles=\"dashed\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.title(\"Term: \" + TERM + \", Loss: \" + loss_name)\n",
    "    plt.savefig(os.path.join(dir_name, TERM + \"_\" + loss_name + \"_Recall_curve.jpg\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot - F1 score curve\n",
    "    plt.plot(thresholds, loss_f1 , label=\"f1\", color=\"tab:red\")\n",
    "    plt.vlines(thresholds[max_f1], 0, loss_f1[max_f1], colors=\"black\",linestyles=\"dashed\")\n",
    "    plt.hlines(loss_f1[max_f1], 0, thresholds[max_f1], colors=\"black\",linestyles=\"dashed\")\n",
    "    plt.ylabel(\"F1 score\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.title(\"Term: \" + TERM + \", Loss: \" + loss_name)\n",
    "    plt.savefig(os.path.join(dir_name, TERM + \"_\" + loss_name + \"_F1_curve.jpg\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot - IOU curve\n",
    "    plt.plot(thresholds, loss_IOU , label=\"IOU\", color=\"tab:purple\")\n",
    "    plt.vlines(thresholds[max_IOU], 0, loss_IOU[max_IOU], colors=\"black\",linestyles=\"dashed\")\n",
    "    plt.hlines(loss_IOU[max_IOU], 0, thresholds[max_IOU], colors=\"black\",linestyles=\"dashed\")\n",
    "    plt.ylabel(\"IOU\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.title(\"Term: \" + TERM + \", Loss: \" + loss_name)\n",
    "    plt.savefig(os.path.join(dir_name, TERM + \"_\" + loss_name + \"_IOU_curve.jpg\"))\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    print(\"ALL FOLDS TRAINING ENDED\")\n",
    "    print(\"Mean best validation: {}\".format(np.mean(fold_validation)))\n",
    "    print(\"Mean precision: {}\".format(np.mean(fold_precision)))\n",
    "    print(\"Mean recall: {}\".format(np.mean(fold_recall)))\n",
    "    print(\"Mean F1: {}\".format(np.mean(fold_f1)))\n",
    "    print(\"Mean IOU: {}\".format(np.mean(fold_IOU)))\n",
    "\"\"\"term loop end\"\"\"\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
